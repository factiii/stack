# Factiii Stack Standards

This document defines the architecture, patterns, and requirements for Factiii Stack plugins.

## Plugin Categories

All plugins must belong to one of four categories:

### 1. PIPELINES
CI/CD systems that trigger deployments.

**Examples:** GitHub Actions, GitLab CI, Jenkins

**Responsibilities:**
- Generate workflow files (ultra-thin, only trigger + pass secrets)
- Manage pipeline secrets (SSH keys, API tokens)
- Check runtime prerequisites (Node.js, CLI tools)
- **Control routing** via `canReach()` and `deployStage()` methods
- Orchestrate plugin execution via scan/fix/deploy

**Required Methods for Pipeline Plugins:**

Pipeline plugins MUST implement these methods:

```typescript
// STATIC: How can this pipeline reach each stage?
static canReach(stage: Stage, config: FactiiiConfig): Reachability {
  // Returns: { reachable: true, via: 'local' | 'workflow' | 'github-api' }
  // Or:      { reachable: false, reason: 'Missing GITHUB_TOKEN' }
}

// INSTANCE: Deploy to a stage - handles routing
async deployStage(stage: Stage, options: DeployOptions): Promise<DeployResult> {
  const reach = MyPipeline.canReach(stage, this.config);
  
  if (!reach.reachable) {
    return { success: false, error: reach.reason };
  }
  
  if (reach.via === 'workflow') {
    // Trigger workflow instead of direct execution
    await this.triggerWorkflow('deploy.yml', { environment: stage });
    return { success: true, message: 'Workflow triggered' };
  }
  
  // via: 'local' - execute directly
  return this.runLocalDeploy(stage, options);
}
```

**The Four Stages:**

All pipelines must understand these stages and how to reach them:

| Stage | Description | Typical Access |
|-------|-------------|----------------|
| `dev` | Local development | Always local |
| `secrets` | Secret store (GitHub Secrets, Vault, etc.) | API access |
| `staging` | Staging server | Workflow or local (if on server) |
| `prod` | Production server | Workflow or local (if on server) |

**Example: GitHub Actions Pipeline Routing:**

```typescript
static canReach(stage: Stage, config: FactiiiConfig): Reachability {
  switch (stage) {
    case 'dev':
      return { reachable: true, via: 'local' };
    
    case 'secrets':
      if (!process.env.GITHUB_TOKEN) {
        return { reachable: false, reason: 'Missing GITHUB_TOKEN' };
      }
      return { reachable: true, via: 'github-api' };
    
    case 'staging':
    case 'prod':
      // On server (in workflow): run locally
      if (process.env.GITHUB_ACTIONS) {
        return { reachable: true, via: 'local' };
      }
      // On dev machine: trigger workflow
      return { reachable: true, via: 'workflow' };
  }
}
```

## Stage Execution Pattern

**Environment Variables That Affect Routing:**

| Variable | Purpose |
|----------|---------|
| `GITHUB_ACTIONS` | Set in GitHub Actions. `canReach()` returns `'local'` for all stages. |
| `FACTIII_ON_SERVER` | Set when running on server (non-GitHub). `canReach()` returns `'local'`. |

**CRITICAL: This pattern has been broken 500+ times. Read carefully.**

### How Commands Work

All commands (scan, fix, deploy) follow this pattern:

1. User specifies stage: `--dev`, `--secrets`, `--staging`, `--prod` (or no flag = all stages)
2. Command groups all plugin fixes by their `stage` property
3. For each requested stage, asks **pipeline plugin**: `canReach(stage)?`
   - `{ reachable: true, via: 'local' }` â†’ run fixes locally
   - `{ reachable: true, via: 'workflow' }` â†’ pipeline triggers workflow with `--staging` or `--prod`
   - `{ reachable: false, reason: '...' }` â†’ show error, stop

### Key Principle: Commands are DUMB

- `scan.ts`, `fix.ts`, `deploy.ts` do NOT know about GITHUB_TOKEN, SSH, workflows
- They ONLY ask the pipeline plugin: "can you reach this stage?"
- The **pipeline plugin** decides what's needed (tokens, SSH keys, etc.)
- This keeps commands compatible with ANY pipeline plugin

### Command Responsibilities

**init** (first-time setup)
- Scans codebase and creates stack.yml with EXAMPLE_ vars
- Interactive vault/secrets setup (password, SSH keys, credentials)
- Only runs once (or with --force to regenerate)

**scan** (read-only â€” MUST NOT modify any files, ever)
- Only runs scan() functions to detect problems
- Reports issues with severity levels (critical, warning, info)
- Returns problems list for fix/deploy to act on
- If scan modifies anything, it is a bug

**fix** (safe changes only â€” MUST NOT touch deployment artifacts)
- Creates/updates config files (stack.yml, stackAuto.yml, stack.local.yml)
- Installs CLI tools (brew, ansible, eas-cli, docker, etc)
- Creates workflow files, start.sh, .gitignore entries
- MUST NOT touch:
  - docker-compose.yml (generated by deploy)
  - nginx configs (generated by deploy)
  - Docker containers (managed by deploy)
  - SSL certificates (managed by deploy)
- If a deployment artifact is broken, fix should tell user:
  "Run `npx stack deploy --{stage}` to regenerate"

**deploy** (deployment changes)
- Modifies deployment artifacts: docker-compose, nginx, containers, SSL
- Delegates to pipeline plugin's deployStage()
- Runs scan first â€” blocks on critical issues
- Handles: docker build, compose up/down, nginx reload, SSL setup

### Pipeline Plugin Responsibilities

The pipeline plugin implements `canReach()` which returns how to reach each stage:

```typescript
canReach(stage: Stage, config: FactiiiConfig): Reachability {
  // For Factiii (GitHub Actions) pipeline:
  //   - dev: always local
  //   - secrets: needs GITHUB_TOKEN
  //   - staging/prod: 
  //       - If GITHUB_ACTIONS=true â†’ local (we're on the server)
  //       - Else â†’ workflow (trigger GitHub Actions)
}
```

### When Pipeline Triggers a Workflow

When `canReach()` returns `via: 'workflow'`, the pipeline triggers a workflow that:
1. SSHs to the target server
2. Runs the command with the specific stage flag: `npx stack fix --staging`

**CRITICAL: Workflows MUST specify --staging or --prod**

```bash
# Correct - specifies which stage to run
GITHUB_ACTIONS=true npx stack fix --staging

# WRONG - will try to run all stages, may trigger more workflows
npx stack fix
```

On the server, the command:
- Doesn't know it's on a remote server
- Just runs staging fixes locally
- `canReach('staging')` returns 'local' because `GITHUB_ACTIONS=true`

### Dependency Chain

```
dev      â†’ Always reachable locally
secrets  â†’ Needs GITHUB_TOKEN (to access GitHub Secrets API)
staging  â†’ Needs workflow OR GITHUB_ACTIONS=true
prod     â†’ Needs workflow OR GITHUB_ACTIONS=true
```

## Stage Batching Architecture

**CRITICAL: Avoid multiple SSH connections per stage.**

All scan/fix operations must be batched by stage to minimize SSH overhead and maintain clean execution flow.

### Scan Batching Flow

1. **Collect** - Gather all fixes for requested stages from all plugins
2. **Bundle** - Group fixes by stage (all dev, all staging, all prod)
3. **Execute** - CLI asks pipeline `canReach(stage)` for each stage:
   - `via: 'local'` â†’ run all scans locally in one pass
   - `via: 'workflow'` â†’ trigger workflow (workflow SSHs once and runs with `--staging` or `--prod`)
4. **Return** - Results per stage: `{dev: Fix[], secrets: Fix[], staging: Fix[], prod: Fix[]}`

### Fix Batching Flow

1. **Scan first** - Get bundled results from scan
2. **Execute fixes** - For each stage with problems:
   - Run all fixes for that stage in ONE session
   - No SSH calls from individual fix functions
3. **Return** - Per stage: `{fixed: N, manual: N, failed: N}`

### Deploy Flow

1. **Scan with bundler** - Check all stages
2. **Block if issues** - Show why, exit
3. **Deploy if clean** - Proceed with deployment

### Individual Fix Function Rules

**NEVER in fix scan/fix functions:**
- Check `GITHUB_ACTIONS` or other env vars to determine context
- Call SSH or remote execution
- Assume execution context

**ALWAYS in fix scan/fix functions:**
- Assume running locally on target machine
- Use `execSync` for local commands
- Return boolean (scan) or boolean (fix)

**CLI/Workflow handles:**
- Asking pipeline `canReach(stage)` to determine execution method
- SSH execution (via workflow, ONE call per stage)
- Workflow triggering for remote stages

### Result Format

Clean, per-stage breakdown showing **what was fixed and how to fix manual issues**:

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RESULTS BY STAGE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DEV:
   âœ… Fixed: GitHub workflows may be outdated
   âœ… Fixed: Missing .env.example entries

STAGING:
   ğŸ“ Manual: Commit workflows
      â†’ git add .github/workflows/ && git commit -m "Update workflows" && git push

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: Fixed: 2, Manual: 1, Failed: 0
```

**CRITICAL: Always show issue details, not just counts. Users need to know WHAT was fixed and HOW to fix manual issues.**

**CRITICAL: Workflow Files Must Be Ultra-Thin**

Pipeline plugins generate workflow files, but these files should contain MINIMAL logic:

**Workflows should ONLY:**
- Trigger the deployment
- Pass secrets (SSH keys, AWS credentials)
- **Bootstrap Node.js (one-time prerequisite)** - Check if Node.js exists, install if missing
- SSH to server and run CLI command

**Workflows should NEVER contain:**
- Server setup logic (Docker, git installation, pnpm, etc.)
- Repository cloning/pulling
- Dependency installation
- Build logic
- Bash scripts longer than 10 lines

**Why?** All logic belongs in plugins (scan/fix/deploy methods), not workflows.

**Exception: Node.js Bootstrap**

Workflows include a one-time Node.js bootstrap step to solve the chicken-and-egg problem:
- `npx stack` requires Node.js to run
- But we want plugins to handle Node.js installation
- Solution: Workflows check if Node.js exists and install if missing (one-time)
- After bootstrap, plugins verify Node.js is present for ongoing operations

This is the ONLY server setup logic allowed in workflows.

**Versioning Generated Files**

All files generated by Factiii Stack MUST include a version comment for audit purposes:

**Format:**
```yaml
# Generated by @factiii/stack v2.0.0
```

**Why:**
- Enables version mismatch detection (outdated workflows)
- Provides audit trail for debugging
- Allows automated validation during scan/fix
- Makes it clear which version of the tool generated the file

**Applies to:**
- GitHub workflow files (`.github/workflows/*.yml`)
- Docker compose files (`docker-compose.yml`)
- Nginx configs (`nginx.conf`)
- Any other generated configuration files

**Implementation:**
Plugins that generate files should:
1. Read the package version from `package.json`
2. Inject a version comment at the top of generated files
3. Update the version comment when regenerating files
4. Provide a fix to detect version mismatches

**Correct workflow pattern:**
```yaml
ssh -i ~/.ssh/deploy_key "$USER@$HOST" \
  "COMMIT_HASH=$COMMIT_HASH BRANCH=$BRANCH GITHUB_REPO=$GITHUB_REPO \
   npx stack deploy --staging --commit=$COMMIT_HASH --branch=$BRANCH"
```

**The CLI handles everything:**
1. `deploy.js` runs `scan` first (checks all plugins for issues)
2. If issues found: abort or fix (depending on command)
3. If no issues: delegates to pipeline plugin's `deployStage()` method
4. Pipeline checks `canReach()` to determine routing:
   - `via: 'local'` â†’ Calls server plugin's `ensureServerReady()` then `deploy()`
   - `via: 'workflow'` â†’ Triggers workflow (which runs CLI on server)

**Plugin Orchestration:**

Pipeline plugins must implement scan/fix/deploy methods that check their own prerequisites:

```javascript
static fixes = [
  {
    id: 'node-not-installed-staging',
    stage: 'staging',
    severity: 'critical',
    description: 'Node.js not installed on staging server',
    scan: async (config, rootDir) => {
      // Check if Node.js exists on server
      const { sshExec } = require('../../utils/ssh-helper');
      try {
        await sshExec(config.environments.staging, 'which node');
        return false; // Node.js exists
      } catch {
        return true; // Node.js missing
      }
    },
    fix: async (config, rootDir) => {
      // Install Node.js on server
      const { sshExec } = require('../../utils/ssh-helper');
      await sshExec(config.environments.staging, 'brew install node || ...');
      return true;
    }
  }
]
```

**How Plugins Merge:**

When `deploy.js` runs, it:
1. Loads ALL plugins (pipeline, server, framework, addon)
2. Collects ALL fixes from all plugins
3. Runs scan on all fixes
4. Merges results by stage (dev, secrets, staging, prod)
5. If blocking issues found: abort or fix
6. If no issues: proceed with deployment

This ensures:
- Pipeline checks Node.js availability
- Server plugins check Docker, git, pnpm
- Framework plugins check dependencies, configs
- All checks run together, issues reported together

### 2. SERVERS (OS Types)
Operating system types that handle OS-specific commands and package management.

**Available OS Types:**
- `mac` - macOS (Homebrew, launchctl)
- `ubuntu` - Ubuntu Linux (apt, systemd)
- `windows` - Windows Server (Chocolatey, Windows Services)
- `amazon-linux` - Amazon Linux 2023 (dnf, systemd)
- `alpine` - Alpine Linux (apk) - for containers

**Responsibilities:**
- OS-specific package installation commands (Docker, Node.js, git)
- OS-specific service management
- Provide OS-specific scan/fix operations

**Server plugins are NOT deployment targets.** They define how to interact with
a specific operating system. Pipelines (like AWS, factiii) handle deployment
orchestration and specify which OS types they support.

**Required Static Properties for Server Plugins:**
```typescript
static readonly os: ServerOS = 'ubuntu';           // OS type
static readonly packageManager: PackageManager = 'apt';  // Package manager
static readonly serviceManager: ServiceManager = 'systemd'; // Service manager
```

**OS-Specific Installation Examples:**
```typescript
// Ubuntu
static getDockerInstallCommand(): string {
  return 'sudo apt-get update && sudo apt-get install -y docker.io';
}

// macOS
static getDockerInstallCommand(): string {
  return 'brew install --cask docker';
}

// Windows
static getDockerInstallCommand(): string {
  return 'choco install docker-desktop -y';
}
```

### 3. FRAMEWORKS
Application frameworks and databases.

**Examples:** Prisma+tRPC, Next.js, Expo

**Responsibilities:**
- Detect framework presence
- Run migrations
- Build and prepare applications

### 4. ADDONS
Extensions to frameworks and infrastructure.

**Examples:** Auth (Clerk, Auth.js), Payments (Stripe), Storage (S3), Server Mode

**Responsibilities:**
- Configure integrations
- Validate API keys
- Setup SDK clients
- Provide cross-cutting functionality

**Server Mode Addon:**

The `server-mode` addon configures machines as deployment servers:
- Disables sleep/suspend
- Enables SSH
- Configures firewall rules
- Provides OS-specific server hardening

Enable in stack.yml:
```yaml
staging:
  domain: 192.168.1.100
  server: mac
  server_mode: true   # Enable server hardening (default: true)
```

Server-mode fixes are OS-aware and only run relevant fixes for the target OS.

## Plugin Structure

### Required Static Properties

```javascript
class MyPlugin {
  // REQUIRED
  static id = 'my-plugin';           // Unique identifier
  static category = 'framework';      // pipeline|server|framework|addon
  static version = '1.0.0';          // Semantic version
  
  // REQUIRED: Config schemas
  static configSchema = {};          // User-editable (stack.yml)
  static autoConfigSchema = {};      // Auto-detected (stackAuto.yml)
  
  // REQUIRED: Fixes array
  static fixes = [];                 // Issues this plugin can detect/fix
  
  // REQUIRED: shouldLoad method
  static async shouldLoad(rootDir, config = {}) {
    // Return true if plugin is relevant to this project
    return false;
  }
  
  // OPTIONAL
  static requiredEnvVars = [];       // Environment variables needed
  static helpText = {};              // Help text for secrets/config
}
```

### Plugin File Organization Standard

For plugins with substantial code (1000+ lines), organize files using this standard structure:

```
src/plugins/{category}/{plugin-name}/
â”œâ”€â”€ index.ts                    # Main plugin class, imports everything
â”œâ”€â”€ scanfix/                    # Scan/fix operations organized by concern
â”‚   â”œâ”€â”€ docker.ts              # Docker-related fixes
â”‚   â”œâ”€â”€ node.ts                # Node.js/pnpm fixes
â”‚   â”œâ”€â”€ git.ts                 # Git-related fixes
â”‚   â”œâ”€â”€ containers.ts          # Container management fixes
â”‚   â””â”€â”€ config.ts              # Configuration checks
â”œâ”€â”€ staging.ts                 # Staging-specific operations (if applicable)
â”œâ”€â”€ dev.ts                     # Dev-specific operations (if applicable)
â”œâ”€â”€ prod.ts                    # Production-specific operations (if applicable)
â””â”€â”€ secrets.ts                 # Secrets-specific operations (if applicable)
```

**Structure Guidelines:**

1. **scanfix/** folder - Scan/fix operations organized by concern
   - Each file exports an array of `Fix[]` objects
   - Files group related fixes together (e.g., all Docker fixes in `docker.ts`)
   - Import and combine all arrays in `index.ts`: `static readonly fixes = [...dockerFixes, ...nodeFixes, ...]`

2. **Environment-specific files** - Operations for each environment
   - `dev.ts` - Dev environment operations (e.g., `deployDev`)
   - `staging.ts` - Staging operations (e.g., `deployStaging`, `ensureServerReady`)
   - `prod.ts` - Production operations (e.g., `buildProdImage`)
   - `secrets.ts` - Secrets operations (if plugin handles secrets)
   - **Only create files if they have content** (no blank files)

3. **index.ts** - Main plugin class
   - Static metadata (id, name, category, version)
   - `shouldLoad()` - Determines if plugin should load
   - Imports and combines all scanfix arrays into `static readonly fixes`
   - Imports and uses environment-specific methods
   - Maintains public API compatibility
   - **Must include documentation at top** explaining the plugin structure standard

**When each environment file is used:**
- `dev.ts`: When deploying to local dev environment
- `staging.ts`: When deploying to staging server or preparing staging server
- `prod.ts`: When deploying to production or building production images
- `secrets.ts`: When managing secrets for the plugin

**How scanfix files are organized:**
- Group fixes by the tool/technology they check (docker, node, git, containers, config)
- Each file should have a clear, single responsibility
- Use descriptive file names that indicate what types of fixes they contain

**Example index.ts structure:**

```typescript
/**
 * My Plugin
 *
 * ============================================================
 * PLUGIN STRUCTURE STANDARD
 * ============================================================
 *
 * This plugin follows a standardized structure for clarity and maintainability:
 *
 * **scanfix/** - Scan/fix operations organized by concern
 *   - Each file exports an array of Fix[] objects
 *   - Files group related fixes together
 *   - All fixes are combined in the main plugin class
 *
 * **Environment-specific files** - Operations for each environment
 *   - dev.ts - Dev environment operations
 *   - staging.ts - Staging operations
 *   - prod.ts - Production operations
 *   - Only create files if they have content (no blank files)
 *
 * **index.ts** - Main plugin class
 *   - Static metadata, shouldLoad(), imports everything
 *   - Maintains public API compatibility
 * ============================================================
 */

import { dockerFixes } from './scanfix/docker.js';
import { nodeFixes } from './scanfix/node.js';
import { deployDev } from './dev.js';
import { deployStaging } from './staging.js';

class MyPlugin {
  static readonly id = 'my-plugin';
  static readonly fixes = [...dockerFixes, ...nodeFixes];
  
  async deploy(config, environment) {
    if (environment === 'dev') {
      return deployDev();
    } else if (environment === 'staging') {
      return deployStaging(config);
    }
  }
}
```

**Benefits of this structure:**
- **Clarity**: Easy to find what runs in which environment
- **Maintainability**: Related code is grouped together
- **Scalability**: Easy to add new fixes or environment operations
- **Consistency**: All plugins follow the same pattern

### Config Schemas

#### configSchema - User-Editable Settings

Define settings that users must or can configure:

```javascript
static configSchema = {
  my_plugin: {
    api_key: 'EXAMPLE_your-api-key',  // EXAMPLE_ prefix for required
    endpoint: 'https://api.example.com',
    timeout: 5000                       // Optional with default
  }
};
```

This gets merged into `stack.yml`:

```yaml
name: my-app
environments: {...}
my_plugin:
  api_key: EXAMPLE_your-api-key
  endpoint: https://api.example.com
  timeout: 5000
```

#### autoConfigSchema - Auto-Detected Settings

Define what your plugin can auto-detect:

```javascript
static autoConfigSchema = {
  has_my_plugin: 'boolean',
  my_plugin_version: 'string',
  my_plugin_config_path: 'string'
};
```

#### shouldLoad() - Plugin Relevance Detection

Determine if this plugin should be loaded for the project:

```javascript
static async shouldLoad(rootDir, config = {}) {
  // Check if this plugin is relevant to the project
  // Called during 'npx stack init' to decide which plugins to include
  
  const pkgPath = path.join(rootDir, 'package.json');
  if (!fs.existsSync(pkgPath)) return false;
  
  const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
  const deps = { ...pkg.dependencies, ...pkg.devDependencies };
  
  // Return true if plugin's dependencies are present
  return !!deps['my-plugin'];
}
```

**When shouldLoad() is called:**
- During `npx stack init` - to determine which plugins to include in configs
- During `npx stack scan/fix/deploy` - to load only relevant plugins

**Examples:**

```javascript
// Always load (pipeline plugins)
static async shouldLoad(rootDir, config = {}) {
  return true;
}

// Load if detected in package.json (framework plugins)
static async shouldLoad(rootDir, config = {}) {
  const pkg = JSON.parse(fs.readFileSync(path.join(rootDir, 'package.json'), 'utf8'));
  const deps = { ...pkg.dependencies, ...pkg.devDependencies };
  return !!deps['my-framework'];
}

// Load if config exists or as default (server plugins)
static async shouldLoad(rootDir, config = {}) {
  // If config has our settings, load
  if (config?.my_server?.api_key) return true;
  
  // On init (no config), load as default
  return Object.keys(config).length === 0;
}
```

#### detectConfig() - Auto-Detection Logic

Implement detection logic:

```javascript
static async detectConfig(rootDir) {
  const pkgPath = path.join(rootDir, 'package.json');
  if (!fs.existsSync(pkgPath)) return null;
  
  const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
  const deps = { ...pkg.dependencies, ...pkg.devDependencies };
  
  if (!deps['my-plugin']) return null;
  
  return {
    has_my_plugin: true,
    my_plugin_version: deps['my-plugin'].replace(/^[\^~]/, ''),
    my_plugin_config_path: this.findConfig(rootDir)
  };
}
```

## Fixes Array

The `fixes` array is the core of the plugin system. Each fix defines:
- What to scan for (the `scan()` function)
- How to fix it (the `fix()` function)
- Manual instructions if auto-fix not possible

### Fix Structure

```javascript
static fixes = [
  {
    id: 'unique-fix-id',
    stage: 'dev',              // dev|secrets|staging|prod
    severity: 'critical',      // critical|warning|info
    description: 'Human-readable description',

    // Optional: Only run on specific OS types
    os: 'ubuntu',              // mac|ubuntu|windows|amazon-linux|alpine
    // Or multiple OS types:
    // os: ['ubuntu', 'amazon-linux'],

    // Scan function - returns true if problem exists
    scan: async (config, rootDir) => {
      return !config.my_plugin?.api_key;
    },

    // Fix function - returns true if fixed successfully
    fix: async (config, rootDir) => {
      // Auto-fix logic
      return true;
    },

    // Manual fix instructions
    manualFix: 'Add api_key to stack.yml'
  }
];
```

**OS Filtering:**

Fixes can optionally specify which OS types they apply to:
- If `os` is not set, the fix runs on all OS types
- If `os` is a string, the fix only runs on that OS
- If `os` is an array, the fix runs on any of those OS types

The pipeline filters fixes based on the target environment's `server` field.

### The Four Stages

Every fix must specify which stage it applies to:

**dev** - Local development
- Check local dependencies
- Validate configuration files
- Ensure dev tools installed

**secrets** - GitHub/Pipeline secrets
- Validate GitHub secrets exist
- Check API keys are set
- Verify credentials

**staging** - Staging server
- Check server connectivity
- Validate staging environment
- Ensure staging database exists

**prod** - Production server
- Check production connectivity
- Validate production environment
- Ensure production database exists

### Severity Levels

**critical** - Blocks deployment
- Missing required configuration
- Invalid credentials
- Server unreachable

**warning** - Should be fixed but not blocking
- Outdated dependencies
- Suboptimal configuration
- Missing optional features

**info** - Informational only
- Suggestions for improvement
- Best practice recommendations

## Deploy Method

Every plugin must implement a `deploy()` method:

```javascript
async deploy(config, environment) {
  if (environment === 'dev') {
    // Start local development
    return this.deployDev(config);
  } else if (environment === 'staging') {
    // Deploy to staging
    return this.deployStaging(config);
  } else if (environment === 'prod') {
    // Deploy to production
    return this.deployProd(config);
  }
  
  return { success: false, error: 'Unsupported environment' };
}
```

Return format:

```javascript
{
  success: true|false,
  message: 'Optional success message',
  error: 'Optional error message'
}
```

## Environment Variables

Plugins can declare required environment variables:

```javascript
static requiredEnvVars = [
  'DATABASE_URL',
  'API_KEY',
  'SECRET_TOKEN'
];
```

The system automatically generates fixes to validate these exist in:
- `.env.example` (dev stage)
- `.env.staging` (staging stage)
- `.env.prod` (prod stage)

## Plugin Lifecycle

### 1. Load
Plugins are loaded from:
- `src/plugins/pipelines/`
- `src/plugins/servers/`
- `src/plugins/frameworks/`
- `src/plugins/addons/`
- `node_modules/@factiii/stack-plugin-*`

### 2. Scan
When `npx stack scan` runs:
1. All plugins' `fixes` arrays are collected
2. Each fix's `scan()` function is called
3. Problems are grouped by stage
4. Results are displayed to user

### 3. Fix
When `npx stack fix` runs:
1. Scan is run first to find problems
2. Fixes are reordered by stage (dev â†’ secrets â†’ staging â†’ prod)
3. Each fix's `fix()` function is called
4. Manual fixes are displayed for unfixable issues

### 4. Deploy
When `npx stack deploy --{env}` runs:
1. Scan is run first - aborts if problems found
2. Environment-specific `.env` file is loaded
3. Each plugin's `deploy()` method is called
4. Health checks are performed

## Example Plugin Implementation

```javascript
const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

class MyFrameworkPlugin {
  // ============================================================
  // STATIC METADATA
  // ============================================================
  
  static id = 'my-framework';
  static name = 'My Framework';
  static category = 'framework';
  static version = '1.0.0';
  
  static requiredEnvVars = ['DATABASE_URL'];
  
  // ============================================================
  // CONFIG SCHEMAS
  // ============================================================
  
  static configSchema = {
    my_framework: {
      migrations_path: null  // Optional override
    }
  };
  
  static autoConfigSchema = {
    has_my_framework: 'boolean',
    my_framework_version: 'string'
  };
  
  // ============================================================
  // AUTO-DETECTION
  // ============================================================
  
  static async detectConfig(rootDir) {
    const pkgPath = path.join(rootDir, 'package.json');
    if (!fs.existsSync(pkgPath)) return null;
    
    const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
    const deps = { ...pkg.dependencies, ...pkg.devDependencies };
    
    if (!deps['my-framework']) return null;
    
    return {
      has_my_framework: true,
      my_framework_version: deps['my-framework'].replace(/^[\^~]/, '')
    };
  }
  
  // ============================================================
  // FIXES
  // ============================================================
  
  static fixes = [
    {
      id: 'missing-my-framework',
      stage: 'dev',
      severity: 'info',
      description: 'My Framework not detected',
      scan: async (config, rootDir) => {
        const detected = await this.detectConfig(rootDir);
        return !detected;
      },
      fix: null,
      manualFix: 'Install: npm install my-framework'
    },
    {
      id: 'pending-migrations-staging',
      stage: 'staging',
      severity: 'warning',
      description: 'Database migrations pending on staging',
      scan: async (config, rootDir) => {
        // Check if migrations are pending
        return await this.hasPendingMigrations('staging');
      },
      fix: async (config, rootDir) => {
        await this.runMigrations('staging');
        return true;
      },
      manualFix: 'Run: npx my-framework migrate'
    }
  ];
  
  // ============================================================
  // DEPLOYMENT
  // ============================================================
  
  async deploy(config, environment) {
    if (environment === 'dev') {
      console.log('   Running dev migrations...');
      execSync('npx my-framework migrate:dev', { stdio: 'inherit' });
    } else {
      console.log(`   Running ${environment} migrations...`);
      execSync('npx my-framework migrate:deploy', { stdio: 'inherit' });
    }
    
    return { success: true, message: 'Migrations complete' };
  }
  
  // ============================================================
  // HELPER METHODS
  // ============================================================
  
  async hasPendingMigrations(environment) {
    // Implementation
  }
  
  async runMigrations(environment) {
    // Implementation
  }
}

module.exports = MyFrameworkPlugin;
```

## External Plugin Development

### 1. Create Plugin Package

```bash
mkdir my-factiii-plugin
cd my-factiii-plugin
npm init -y
```

### 2. Implement Plugin

Create `index.js` following the structure above.

### 3. Export Plugin

```javascript
// index.js
class MyPlugin {
  // ... implementation
}

module.exports = MyPlugin;
```

### 4. Publish

```bash
npm publish
```

### 5. Use in Projects

```bash
npm install my-factiii-plugin
```

Add to `stack.yml`:

```yaml
plugins:
  - my-factiii-plugin
```

## Best Practices

### 1. Single Responsibility
Each plugin should handle one domain (one framework, one server type, etc.)

### 2. Idempotent Operations
Fixes and deployments should be safe to run multiple times.

### 3. Clear Error Messages
Always provide actionable error messages and manual fix instructions.

### 4. Fail Fast
Validate configuration early in the scan phase, not during deployment.

### 5. Minimal Workflows
Keep GitHub Actions workflows thin - just SSH and call CLI.

### 6. Test Locally
All deployment logic should be testable locally via `npx stack deploy --dev`.

### 7. Document Everything
Provide clear `helpText` for all secrets and configuration options.

## Plugin Approval

To get your plugin approved and listed in `approved.json`:

1. Open a PR to this repository
2. Add your plugin to `src/plugins/approved.json`
3. Include:
   - Plugin source code or npm package link
   - Documentation
   - Example usage
   - Test results

Approved plugins load without warnings. Unapproved plugins show a warning but still work.

## Server-Side Architecture

### Multi-Repo Deployment

Factiii Stack supports deploying multiple repos to the same server. Each server runs a single nginx reverse proxy that routes to all deployed apps.

### Server Directory Structure

```
~/.factiii/                          # Root infrastructure directory
â”œâ”€â”€ repo-name/                       # Each deployed repo
â”‚   â”œâ”€â”€ stack.yml                    # Repo config (scanned by generate-all.js)
   â”‚   â”œâ”€â”€ stackAuto.yml              # Auto-detected config
â”‚   â”œâ”€â”€ .env.staging                 # Secrets (staging server only)
â”‚   â”œâ”€â”€ .env.prod                    # Secrets (prod server only)
â”‚   â””â”€â”€ ... (source code if requiresFullRepo=true)
â”œâ”€â”€ repo-name-2/                     # Another deployed repo
â”‚   â”œâ”€â”€ stack.yml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate-all.js              # Regenerates merged configs
â”œâ”€â”€ docker-compose.yml               # MERGED from all repos (generated)
â””â”€â”€ nginx.conf                       # MERGED from all repos (generated)
```

**Key principle**: Staging and prod are **independent servers**. Each server only has its own environment's secrets.

### Pipeline Plugin: requiresFullRepo()

Pipeline plugins can declare whether they need the full repo cloned on the server:

```javascript
static requiresFullRepo(environment) {
  // Return true if full repo needed (for building from source)
  // Return false if only stack.yml + env file needed (pulls pre-built images)
  return environment === 'staging';
}
```

**Factiii Pipeline defaults:**
- `staging` -> `true` (needs full repo to build locally)
- `prod` -> `false` (pulls pre-built images from ECR)

### The generate-all.js Script

This is the core server-side script that:

1. Scans `~/.factiii/*/stack.yml` (or factiii.yml) for all deployed repos
2. Generates a unified `docker-compose.yml` with all services
3. Generates a unified `nginx.conf` routing to all domains

Run it after any deployment to update configs:

```bash
node ~/.factiii/scripts/generate-all.js
```

### Server Plugin Docker Compose Modifications

Server plugins are responsible for generating and modifying docker-compose.yml files. After calling `generate-all.js`, server plugins can modify the compose file for:

- **Server-specific needs**: Updating image references (e.g., ECR image paths for production)
- **Environment-specific needs**: Adding services required for specific environments (e.g., postgres for staging)

**Standard Pattern:**

```typescript
// 1. Generate base docker-compose.yml
await runGenerateAll();

// 2. Modify for environment-specific needs (e.g., add postgres for staging)
await addPostgresServiceForStaging(config, envConfig);

// 3. Modify for server-specific needs (e.g., update image tags)
await updateComposeForStagingImage(config, envConfig);

// 4. Start containers
await dockerComposeUp();
```

**Example: Adding Postgres Service for Staging**

Server plugins can add services to docker-compose.yml based on environment configuration:

```typescript
async function addPostgresServiceForStaging(
  envConfig: EnvironmentConfig,
  config: FactiiiConfig
): Promise<void> {
  // Read DATABASE_URL from .env.staging
  const databaseUrl = await readEnvFile('.env.staging', 'DATABASE_URL');
  
  // Parse connection details
  const dbConfig = parseDatabaseUrl(databaseUrl);
  
  // Add postgres service to compose
  compose.services.postgres = {
    image: 'postgres:16-alpine',
    environment: {
      POSTGRES_USER: dbConfig.user,
      POSTGRES_PASSWORD: dbConfig.password,
      POSTGRES_DB: dbConfig.database,
    },
    ports: [`${dbConfig.port}:5432`],
    volumes: ['postgres_data:/var/lib/postgresql/data'],
    networks: ['factiii'],
  };
}
```

**When to Modify Compose:**

- **Do modify** for environment-specific services (postgres for staging, redis for caching)
- **Do modify** for server-specific image references (ECR paths, local image tags)
- **Don't modify** for deployment-agnostic services (those should be in generate-all.js)
- **Don't modify** for production managed services (use RDS, ElastiCache, etc. instead of containers)

**Production Considerations:**

Production environments typically use managed services (RDS, ElastiCache) rather than local containers. Server plugins should only add containerized services for staging/development environments where local services are appropriate.

### Deployment Flows

**Staging (requiresFullRepo = true):**
1. Workflow SSHs to staging server
2. Clone/pull full repo to `~/.factiii/{repo}/`
3. Write secrets to `~/.factiii/{repo}/.env.staging`
4. Run `generate-all.js` to regenerate merged configs
5. Build and start: `docker compose up -d {repo}-staging`

**Production (requiresFullRepo = false):**
1. Workflow SSHs to production server
2. Create `~/.factiii/{repo}/` with just `stack.yml`
3. Write secrets to `~/.factiii/{repo}/.env.prod`
4. Run `generate-all.js` to regenerate merged configs
5. Pull image from ECR and start: `docker compose up -d {repo}-prod`

## Architecture Diagrams

### Plugin Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   npx       â”‚
â”‚  factiii    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ scan â”€â”€â”€â”€â”€â”€â”
       â”‚             â”‚
       â”œâ”€ fix â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º Load Plugins
       â”‚             â”‚
       â””â”€ deploy â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Plugin Loader  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Pipeline â”‚ â”‚ Server â”‚ â”‚Frameworkâ”‚
    â”‚ Plugins â”‚ â”‚Plugins â”‚ â”‚ Plugins â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Config Generation

```
Plugin.configSchema â”€â”€â”
                      â”œâ”€â”€â–º Merge â”€â”€â–º stack.yml
Plugin.configSchema â”€â”€â”˜

Plugin.detectConfig() â”€â”€â”
                        â”œâ”€â”€â–º Merge â”€â”€â–º stackAuto.yml
Plugin.detectConfig() â”€â”€â”˜
```

### Deployment Flow

```
npx stack deploy --staging
         â”‚
         â”œâ”€ 1. Scan (abort if problems)
         â”‚
         â”œâ”€ 2. Load .env.staging
         â”‚
         â”œâ”€ 3. Call Plugin.deploy(config, 'staging')
         â”‚      â”‚
         â”‚      â”œâ”€ Pipeline: Trigger workflow
         â”‚      â”œâ”€ Server: Build & start containers
         â”‚      â””â”€ Framework: Run migrations
         â”‚
         â””â”€ 4. Health checks
```

## Summary

Factiii Stack's plugin architecture enables:
- **Modularity**: Each plugin handles one domain
- **Extensibility**: Easy to add new frameworks/servers
- **Testability**: All logic in JavaScript, not bash
- **Clarity**: Clear separation of concerns
- **Maintainability**: Config logic lives with the plugin

For questions or contributions, see the main repository.
